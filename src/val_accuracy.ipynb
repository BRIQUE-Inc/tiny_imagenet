{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiny ImageNet: Validation Accuracy\n",
    "\n",
    "Calculate top-1 and top-5 validation accuracy. 2 methods:\n",
    "\n",
    "1. Feed validation image into model with no distortions\n",
    "2. Feed validation image in with 10 permuations of l/r flip and 5 crops\n",
    "\n",
    "The validation set was used because labels weren't available for the test set.\n",
    "\n",
    "Note: This runs *very* slowly. The images are loaded one-by-one in a loop and fed to the model using a feed_dict. During training, a much more efficient pipeline is used: distortions and QueueRunner on CPU and model on the GPU.\n",
    "\n",
    "*Python Notebook by Patrick Coady: [Learning Artificial Intelligence](https://learningai.io/)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from train import *\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy.ndimage\n",
    "import scipy.misc\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrainConfig(object):\n",
    "    \"\"\"Training configuration\"\"\"\n",
    "    dropout_keep_prob = 1.0  # disable dropout for inference\n",
    "    model_name = 'vgg_16'  # choose model \n",
    "    model = staticmethod(globals()[model_name])\n",
    "    config_name = 'no_hue'  # choose training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(config):\n",
    "    \"\"\"Load most recent checkpoint and make prediction\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        img_ph = tf.placeholder(dtype=tf.uint8, shape=(None, 64, 64, 3))\n",
    "        img = tf.image.crop_to_bounding_box(img_ph, 4, 4, 56, 56)\n",
    "        logits = config.model(img, config)      \n",
    "        top_5 = tf.nn.top_k(logits, k=5, sorted=True)\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            filenames_labels = load_filenames_labels('val')\n",
    "            path = 'checkpoints/' + config.model_name + '/' + config.config_name\n",
    "            saver.restore(sess, tf.train.latest_checkpoint(path))\n",
    "            count, correct1, correct5 = (0, 0, 0)\n",
    "            for filename, label in filenames_labels:\n",
    "                count += 1\n",
    "                np_img = scipy.ndimage.imread(filename, mode='RGB')\n",
    "                np_img = np_img[np.newaxis, :, :, :]\n",
    "                feed_dict = {img_ph: np_img}\n",
    "                top_vals, top_idx = sess.run(top_5, feed_dict=feed_dict)\n",
    "                if top_idx[0][0] == int(label):\n",
    "                    correct1 += 1\n",
    "                if int(label) in top_idx[0]:\n",
    "                    correct5 += 1\n",
    "                    \n",
    "      \n",
    "    return correct1 / count, correct5 / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_10_crop(config):\n",
    "    \"\"\"Load most recent checkpoint and make prediction\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        img_ph = tf.placeholder(dtype=tf.uint8, shape=(64, 64, 3))\n",
    "        crops = [(0,0), (0,8), (8,0), (8,8), (4,4)]\n",
    "        img_list = []\n",
    "        for crop in crops:  # 5 crops * 2 flip l-r\n",
    "            x, y = crop\n",
    "            img = tf.image.crop_to_bounding_box(img_ph, x, y, 56, 56)\n",
    "            img_list.append(img)\n",
    "            img = tf.image.flip_left_right(img)\n",
    "            img_list.append(img)\n",
    "        img = tf.stack(img_list)\n",
    "        ps = tf.nn.softmax(config.model(img, config))\n",
    "        ps = tf.reduce_prod(ps, axis=0, keep_dims=True) \n",
    "        top_k = tf.nn.top_k(ps, k=5, sorted=True)\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            filenames_labels = load_filenames_labels('val')\n",
    "            path = 'checkpoints/' + config.model_name + '/' + config.config_name\n",
    "            saver.restore(sess, tf.train.latest_checkpoint(path))\n",
    "            count, correct1, correct5 = (0, 0, 0)\n",
    "            for filename, label in filenames_labels:\n",
    "                count += 1\n",
    "                np_img = scipy.ndimage.imread(filename, mode='RGB')\n",
    "                feed_dict = {img_ph: np_img}\n",
    "                top_vals, top_idx = sess.run(top_k, feed_dict=feed_dict)\n",
    "                if top_idx[0][0] == int(label):\n",
    "                    correct1 += 1\n",
    "                if int(label) in top_idx[0]:\n",
    "                    correct5 += 1\n",
    "      \n",
    "    return correct1 / count, correct5 / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/vgg_16/no_hue/model-44000\n",
      "Top-1 accuracy (center crop): 0.5185, Top-5 accuracy: 0.7654\n"
     ]
    }
   ],
   "source": [
    "config = TrainConfig()\n",
    "acc = accuracy(config)\n",
    "print('Top-1 accuracy (center crop): {}, Top-5 accuracy: {}'.format(acc[0], acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/vgg_16/no_hue/model-44000\n",
      "Top-1 accuracy (5-crops + l/r flip): 0.5469, Top-5 accuracy: 0.787\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_10_crop(config)\n",
    "print('Top-1 accuracy (5-crops + l/r flip): {}, Top-5 accuracy: {}'.format(acc[0], acc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Results Summary\n",
    "\n",
    "**'baseline' performance**  \n",
    "Top-1 accuracy (center crop): 0.4929, Top-5 accuracy: 0.7478  \n",
    "Top-1 accuracy (5-crops + l/r flip): 0.522, Top-5 accuracy: 0.7723  \n",
    "  \n",
    "**smoothed cross-entropy**  \n",
    "Top-1 accuracy (center crop): 0.4958, Top-5 accuracy: 0.7512  \n",
    "Top-1 accuracy (5-crops + l/r flip): 0.5197, Top-5 accuracy: 0.7695  \n",
    "  \n",
    "*There is no significant improvement from using smoothed cross-entropy loss.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Ablation with Image Distortions Removed\n",
    "\n",
    "### No Flip\n",
    "Top-1 accuracy (center crop): 0.4613, Top-5 accuracy: 0.7156  \n",
    "Top-1 accuracy (5-crops + l/r flip): 0.5127, Top-5 accuracy: 0.7572  \n",
    "\n",
    "### No Crop\n",
    "Top-1 accuracy (center crop): 0.4441, Top-5 accuracy: 0.6986  \n",
    "Top-1 accuracy (5-crops + l/r flip): 0.4979, Top-5 accuracy: 0.7494  \n",
    "\n",
    "### No Saturation\n",
    "Top-1 accuracy (center crop): 0.5254, Top-5 accuracy: 0.7691  \n",
    "Top-1 accuracy (5-crops + l/r flip): 0.5525, Top-5 accuracy: 0.7895  \n",
    "\n",
    "### No Hue\n",
    "Top-1 accuracy (center crop): 0.5286, Top-5 accuracy: 0.771  \n",
    "Top-1 accuracy (5-crops + l/r flip): 0.5644, Top-5 accuracy: 0.7929  \n",
    "\n",
    "### No Saturation / No Hue\n",
    "Top-1 accuracy (center crop): 0.5195, Top-5 accuracy: 0.7621  \n",
    "Top-1 accuracy (5-crops + l/r flip): 0.5482, Top-5 accuracy: 0.7817  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
